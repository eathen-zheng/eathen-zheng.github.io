<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[NTU-ML-Logistic Regression 算法]]></title>
    <url>%2F20180322-NTU-ML-9%2F</url>
    <content type="text"><![CDATA[这一节主要介绍 Logistic Regression 算法。 Logistic RegressionLogistic Regression 是一个分类算法，主要用于二分类的情况，算法预测的是样本属于某个类别的概率，即 $h(\mathbf{x}) = P(+1 | \mathbf{x})$。 因为 $h(\mathbf{x})$ 表示的是一个概率值，为了使其范围在 0 到 1 之间，我们使用了 Logistic 函数$$\theta(s) = \frac{1}{1+e^{-s}}$$ 于是 $$h(\mathbf{x}) = \theta(\mathbf{w}^T\mathbf{x}) = \frac{1}{1+e^{-\mathbf{w}^T\mathbf{x}}}$$ 将取值范围为负无穷到正无穷的 $\mathbf{w}^T\mathbf{x}$ 映射到了 0 到 1。 Logistic Regression Error有了 $h(\mathbf{x})$ 之后，我们还需要找出 $E_{\text{in}}(\mathbf{w})$ 的表达式，在 Logistic Regression 算法中，$E_{\text{in}}(\mathbf{w})$ 是通过最大似然准则得到的。 首先介绍一下似然这个概念。假设我们有一笔数据 $$\mathcal{D}=\big\{ (\mathbf{x}_{1}, +1),\mathbf{x}_{2}, -1),\cdots,\mathbf{x}_{N}, -1), \big\}$$ 那么通过真实的函数 $f$ 得到这批数据的概率可以写成下面的表达式：$$\text{probability}(f) = P(\mathbf{x}_1)f(\mathbf{x}_1) \cdot P(\mathbf{x}_2)(1-f(\mathbf{x}_2)) \cdots P(\mathbf{x}_N)(1-f(\mathbf{x}_N))$$ 同理，通过预测函数 $h$ 得到这批数据的概率可以写成下面的表达式：$$\text{likelihood}(h) = P(\mathbf{x}_1)h(\mathbf{x}_1) \cdot P(\mathbf{x}_2)(1-h(\mathbf{x}_2)) \cdots P(\mathbf{x}_N)(1-h(\mathbf{x}_N))$$我们的目标是要预测 $h$ 使它接近 $f$，而通常来说 $\text{probability}(f)$ 很大，所以我们可以最大化 $\text{likelihood}(h)$。这时意味着 $h$ 生成 $\mathcal{D}$ 的似然（或者说概率）很大，一定程度上可以说，$h \approx f$。 接下来的工作就是要最大化 $\text{likelihood}(h)$$$g = \underset{h}{\text{argmax}} \ \ \text{likelihood}(h)$$ 将常量 $P(\mathbf{x})$ 去掉，同时注意到 $1-h(\mathbf{x}) = h(\mathbf{-x})$，有$$\text{likelihood}(h)\propto \prod \limits_{i=1}^n h(y_n\mathbf{x}_n) = \prod \limits_{i=1}^n \theta(y_n \mathbf{w}^T_n\mathbf{x}_n)$$ 取对数，并做一下相关变换，得到$$\min_\mathbf{w} \frac{1}{N} \sum_{n=1}^{N} -\ln \theta(y_n \mathbf{w}^T \mathbf{x}_n)$$ 即 $$ \min_\mathbf{w} \frac{1}{N} \sum_{n=1}^{N} \ \ln \left( 1 + \text{exp} ( -y_n \mathbf{w}^T \mathbf{x}_n ) \right)$$ 因此，这就是 Logistic Regression 的损失函数$$\text{err}(\mathbf{w}, \mathbf{x}, y) = \ln \left( 1 + \text{exp} ( -y_n \mathbf{w}^T \mathbf{x}_n ) \right)$$ 称之为交叉熵损失函数。 Gradient of Logistic Regression Error为了最小化损失函数$$E_{\text{in}}(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^{N} \ \ln \left( 1 + \text{exp} ( -y_n \mathbf{w}^T \mathbf{x}_n ) \right)$$ 通常采取的方法是梯度下降法，如图所示： 为方便表示，我们使用 $\Box$ 表示 $\left( 1 + \text{exp} ( -y_n \mathbf{w}^T \mathbf{x}_n ) \right)$，使用 $\bigcirc$ 表示 $( -y_n \mathbf{w}^T \mathbf{x}_n )$。 那么求导过程如下：$$\begin{aligned}\frac{\partial E_{\text{in}}(\mathbf{w})}{\partial w_i}&amp;=\frac{1}{N} \sum_{n=1}^{N} \\Big( \frac{\partial \ln (\Box)} {\partial \Box}\Big)\Big( \frac{\partial (1 + \text{exp}(\bigcirc)) } {\partial \bigcirc} \Big)\Big( \frac{\partial -y_n \mathbf{w}^T \mathbf{x}_n} {\partial w_i}\Big)\\&amp;=\frac{1}{N} \sum_{n=1}^{N} \\Big( \frac{1}{\Box} \Big)\Big( \text{exp}(\bigcirc) \Big)\Big( -y_n x_{n,i} \Big)\\&amp;=\frac{1}{N} \sum_{n=1}^{N} \\frac{\text{exp}(\bigcirc)} {1 + \text{exp}(\bigcirc)}\big( -y_n x_{n,i} \big)\\&amp;=\frac{1}{N} \sum_{n=1}^{N} \\theta(\bigcirc) \big( -y_n x_{n,i}\big)\end{aligned}$$ 于是$$\nabla E_{\text{in}}(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^{N} \ \theta \big( -y_n \mathbf{w}^T \mathbf{x}_n \big)\big( -y_n \mathbf{x}_n\big)$$ 我们的目标是使得 $\nabla E_{\text{in}}(\mathbf{w}) = 0$，这里可以分为两种情况 所有 $\theta(\cdot)$ 都为 $0$，这时表示所有 $y_n \mathbf{w}^T \mathbf{x}_n \gg 0$，说明线性可分 加权结果为 $0$，说明线性不可分 Gradient Descent下面来讲一下梯度下降法，这是一种迭代的方法，通过不断的迭代来更新参数的值：$$\mathbf{w}_{t+1} \leftarrow \mathbf{w}_{t} + \eta \mathbf{v}$$ 其中 $\eta$ 表示的是步长，$\mathbf{v}$ 表示的是方向。我们暂时假定步长是给定的，那么在每一次的迭代过程中，等价于求解下面的问题：$$\underset{||\mathbf{v}=1||}{\text{min}} E_{\text{in}}(\mathbf{w}_t + \eta \mathbf{v})$$ 当 $\eta$ 很小的时候，使用泰勒展开，有$$E_{\text{in}}(\mathbf{w}_t + \eta \mathbf{v}) \approx E_{\text{in}}(\mathbf{w}_t) + \eta \mathbf{v}^T \nabla E_{\text{in}}(\mathbf{w}_t)$$ 其中 $E_{\text{in}}(\mathbf{w}_t)$ 以及 $\nabla E_{\text{in}}(\mathbf{w}_t)$ 是已知的，$\eta$ 是正数，于是上式中最佳的 $\mathbf{v}$ 为：$$\mathbf{v} = - \frac{\nabla E_{\text{in}}(\mathbf{w}_t)}{||\nabla E_{\text{in}}(\mathbf{w}_t)||}$$ 于是迭代过程为$$\mathbf{w}_{t+1} \leftarrow \mathbf{w}_{t} - \eta_1 \frac{\nabla E_{\text{in}}(\mathbf{w}_t)}{||\nabla E_{\text{in}}(\mathbf{w}_t)||}$$ 这就是负梯度方向，因此在负梯度方向上 $E_{\text{in}}$ 下降最快。 choice of $\eta$$\eta$ 的大小对 $E_{\text{in}}$ 优化的过程也有一定影响，如下图所示 $\eta$ 太小：优化速度太慢 $\eta$ 太大：优化过程不稳定 因此比较合适的选择是，使 $\eta$ 随着 $||\nabla E_{\text{in}}(\mathbf{w}_t)||$ 变化，于是我们令 $$\eta_2 = \eta_1 \cdot ||\nabla E_{\text{in}}(\mathbf{w}_t)||$$ 带入上面的式子，得到$$\mathbf{w}_{t+1} \leftarrow \mathbf{w}_{t} - \eta_2 ||\nabla E_{\text{in}}(\mathbf{w}_t)|| $$ Logistic Regression Algorithm综合上面的内容，我们得到了 Logistic Regression 算法，如图所示： 以上就是 Logistic Regression 算法的介绍。]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-Linear Regression 算法]]></title>
    <url>%2F20180317-NTU-ML-8%2F</url>
    <content type="text"><![CDATA[这一节主要介绍线性回归算法。 Linear Regression Problem对于输出空间 $\mathcal{Y} = \Bbb{R}$ 的一类问题，一个比较简单的想法就是：将 Linear Classification 的决策函数中的 sign 函数去掉，使用各种特征的加权结果来表示 $y$$$y \approx \sum_{i = 0}^{d} w_i x_i = \textbf{w}^T \textbf{x}$$ 这就是线性回归算法，它的假设空间为 $$h(\textbf{x}) = \textbf{w}^T \textbf{x}$$ 线性回归的目标是寻找一条直线 （$\Bbb{R}^2$） 或者一个平面 （$\Bbb{R}^3$）或者超平面（$\Bbb{R}^n$），使得误差最小，常用的误差函数是平方误差 $$E_{in}(\textbf{w}) = \frac{1}{N} \sum_{n = 1}^{N} \left( h(\textbf{x}_n) - y_n \right)^2$$$$E_{out}(\textbf{w}) = \underset{(x,y) \sim P}{\epsilon} \Big( \textbf{w}^T \textbf{x} - y \Big)$$ Linear Regression Algorithm将 $E_{in}$ 写成矩阵形式$$\begin{split}E_{in}(\textbf{w}) &amp;= \frac{1}{N} \sum_{n = 1}^{N} \left(h(\textbf{x}_n) - y_n\right)^2 \\&amp;= \frac{1}{N} \Bigg\Vert\begin{matrix}\textbf{x}_1^T \textbf{w} - y_1 \\\textbf{x}_2^T \textbf{w} - y_2 \\\cdot \cdot \cdot \\\textbf{x}_N^T \textbf{w} - y_N \\\end{matrix}\Bigg\Vert^2 \\&amp;= \frac{1}{N} \Vert X \textbf{w} - \textbf{y} \Vert^2\end{split}$$其中$$X = \Bigg[\begin{matrix}x_1^T, 1 \\x_2^T, 1 \\\cdot \cdot \cdot \\x_N^T, 1 \\\end{matrix}\Bigg]\in \Bbb{R}^{N \times (d+1)}$$$$\textbf{w} \in \Bbb{R}^{(d+1) \times 1}$$$$\textbf{y} \in \Bbb{R}^{N \times 1}$$我们的目标是找到一个 $\textbf{w}$，使得 $E_{in}(\textbf{w})$ 尽可能小。因此，将 $E_{in}(\textbf{w})$ 对 $\textbf{w}$ 求导，得到：$$\nabla E_{in} (\textbf{w}) = \frac{2}{N} X^T(X\textbf{w} - \textbf{y})$$令$\nabla E_{in}(\textbf{w}) = 0$，得到 $\textbf{w}$ 的最优解 $$\textbf{w}_{\text{LIN}} = \big( X^TX\big)^{-1}X^T\textbf{y}=X^{\dagger}\textbf{y}$$ 其中 $$X^{\dagger}=\big(X^TX\big)^{-1}X^T$$ 称为矩阵 $X$ 的伪逆，于是 $$h(\textbf{x}) = \textbf{w}_{\text{LIN}}^T \textbf{x}$$ 将上面做一个小结，得到 Linear Regression 算法的流程如下： Generalization Issue下面我们来分析一下 Linear Regression 的 $E_{in}$$$\begin{aligned}E_{in}({w_{LIN}})&amp;=\frac{1}{N}||{y-\hat{y}}||^2\\&amp;=\frac{1}{N}||y-XX^{\dagger}y||^2 \\&amp;=\frac{1}{N}||(I-H)y||^2 \\\end{aligned}$$ 其中 $H = XX^{\dagger}$ 是投影矩阵，把 $y$ 投影到 $X$ 的 $d+1$ 个向量构成的平面上，$H$ 有如下的性质： 对称性 $H=H^T$ 幂等性 $H^2=H$ 半正定性 $\lambda_i \geq 0$ $trace(I-{H}) = N-(d+1)$ 假设 $y = f(X) + \text{noise}, f(x) \in \text{span}$，那么如上图所示，有$$\begin{aligned}E_{in}({w_{LIN}})&amp;=\frac{1}{N}||(I-{H})y||^2 \\&amp;=\frac{1}{N}||(I-{H})noise||^2 \\&amp;=\frac{1}{N}trace(I-{H})||noise||^2 \\&amp;=\frac{1}{N}(N-(d+1))||noise||^2\end{aligned}$$ 得到：$$E_{in}({w_{LIN}})=||noise||^2 \cdot \big( 1 - \frac{d+1}{N} \big)$$ $$E_{out}({w_{LIN}})=||noise||^2 \cdot \big( 1 + \frac{d+1}{N} \big)$$两者最终都向 $\sigma^2$ (noise level)收敛，差距是 $\frac{2(d+1)}{N}$，因此说明算法是可行的。 Linear Regression for Binary Classification对比一下 Linear Classification 与 Linear Regression： Linear Regression 用于分类问题 $\mathcal{Y} = \{ +1, -1\}$ $h(\textbf{x})=\text{sign}(\textbf{w}^T\textbf{x})$ NP-hard，难于求解 Linear Regression 用于回归问题 $\mathcal{Y} = \Bbb{R}$ $h(\textbf{x})=\textbf{w}^T\textbf{x}$ 易于求解 因为 $$\text{err}_{0/1} = \big[\big[ \text{sign}(\textbf{w}^T\textbf{x}) \neq y\big]\big] \leq \text{err}_{\text{sqr}} = (\textbf{w}^T\textbf{x} - y)^2$$ 所以可以将 Linear Regression 用于分类问题上： run Linear Regression on binary classification data $\mathcal{D}$ return $g(\textbf{x}) = \text{sign}(\textbf{w}_{\text{LIN}}^T\textbf{x})$ 以上便是 Linear Regression 的内容。]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-错误与噪声]]></title>
    <url>%2F20180313-NTU-ML-7%2F</url>
    <content type="text"><![CDATA[这一节主要讨论在有噪声的情况下，VC维理论是否仍适用。 Noise and Probabilistic Target回顾之前提到的机器学习的流程图，学习的目的，就是找到一个函数 $g$，使得它与目标函数 $f$ 差不多。 然而在现实生活中，往往伴随着噪声： 这些噪声的类别是多种多样的 noise in $y$：如标签标错了 noise in $x$：如原本的数据就存在噪声 没有噪音时，$x$ 服从同一个概率分布 $P$，$y=f(x)$ 是一个固定的值；有噪声时，$x$ 仍然服从同一个概率分布 $P$，$y \sim P(y|x)$ 不再是一个固定的值。 以之前提到的珠子为例子，珠子的两种颜色分别表示了 $h(x)$ 与 $f(x)$ 相等或者不等的情况。我们通过抽样，利用珠子属于某种颜色的频率来估计 $h(x) = f(x)$ 的概率。 在没有噪声的情况下，$y$ 是固定的，因此珠子的颜色是确定的。在有噪声的情况下，$y$ 不是固定的，因此珠子的颜色是变化的，此时我们仍然可以进行抽样的实验，只不过在进行统计的时候，我们记录的是珠子在抽出来那一刻的颜色。这样，我们就可以跟以前一样，通过频率来估计概率。 因此，只要 $x \sim P$ 并且 $y \sim P(y|x)$，也就是说 $(x,y) \sim P(x,y)$，VC维理论仍然适用。于是，学习的目的，从预测 $f$ 变成了预测 $p(y|x)$，其中 $p(y|x)$ 由 $f(x)$ 以及噪声构成。 对于 $f$，我们可以将其想象为分布 $P(y|x)$ 的一种特殊形式。 $y = f(x)$时，$P(y|x) = 1$ $y \neq f(x)$时，$P(y|x) = 0$ 这样就可以将无噪声以及有噪声的情况统一起来，学习的流程图更新成以下形式： Error Measure我们需要有一个准则来衡量所选择的假设函数 $g$ 与目标函数 $f$ 相似程度，通常的方法是定义一个错误函数（也叫做代价函数） $E(g,f)$。 这个错误函数描述的是在整个样本空间（不只是训练样本）中，$g$ 与 $f$ 的相似程度，并且通常来讲，是 $g$ 与 $f$ 在每个样本点上的错误的平均。$$E_{in}(g) = \frac{1}{N} \sum_{n=1}^{N} err \Big( g(x_n), f(x_n) \Big)$$$$E_{out}(g) = \underset{x \sim P}{\epsilon} err \Big( g(x_n), f(x_n) \Big)$$ 常用的两种错误衡量方式 $err \big( g(x), f(x) \big) = err \big( \tilde{y}, y \big)$： 0/1 error for classification：$err \big( \tilde{y}, y \big) = \big[ \tilde{y} \neq y \big] $ squared error for regression：$err \big( \tilde{y}, y \big) = \big( \tilde{y} - y \big) ^ 2 $ 错误衡量准则会对学习过程起到指导作用，因此对于同一个问题，使用不同的错误衡量准则，得到的结果可能不一样。 对机器学习流程图进一步修改，加入了错误衡量的模块，该模块对算法和最终的假设选择都起着很大影响。 Algorithmic Error Measure在现实中，要设计出真正的错误衡量有时候会很困难，在设计错误衡量方式时，常常使用替代的方式 $\hat{err}$： 有意义的错误衡量例如 0/1 error，表示的是 flipping 的噪声，如果 0/1 error 很小，说明出错的样本数很少；例如 squared error，表示的是噪声是高斯的分布，如果 squared error 很小，说明高斯噪声很少； 对设计算法容易的错误衡量例如有闭式解的算法对应的错误衡量方式；例如具有凸函数性质的错误衡量方式。 于是，学习的流程图改为下面的形式，其中 $err$ 表示的是真正的错误衡量方式，而$\hat{err}$ 表示的是我们用在算法中的错误衡量方式，我们使用 $\hat{err}$ 来替代 $err$ 进行算法中的优化以及假设函数的选择。 Weighted Classification我们可以使用 cost matrix 表示 0/1 error 其中 false reject 表示的是把 $y=+1$ 预测为 $y=-1$，false accept 表示的是把 $y=-1$ 预测为 $y=+1$。 当这两类错误的 cost 相等时，表示这两类错误的重要性一致，当这两类错误的 cost 不相等时，表示其中一种错误更加严重，代价更高。 于是我们可以根据实际的需要，赋予两种错误不同的代价，这叫做 weighted classification。 下面是一个 cost matrix 的例子，在这个例子中，把 $y=+1$ 预测为 $y=-1$ 的代价是 $1$，而把 $y=-1$ 预测为 $y=+1$ 的代价是 $1000$，因此算法会惩罚后一种错误分类的情况。 通过改变样本的数目，可以将 weighted classification 转化为一般的 classification。用上一个例子来说明，我们可以将数据集中 $y=-1$ 的样本复制 1000 份，这样就相当于在没有加权的 0/1 error 下进行实验。于是可以使用之前用于 0/1 error 的算法，比如 pocket 算法。 将上面 cost matrix 的转化嵌入到算法中，便得到了 weighted pocket 算法]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-为什么机器能够学习(2)]]></title>
    <url>%2F20180311-NTU-ML-5%2F</url>
    <content type="text"><![CDATA[Restriction of Break Point上次我们说到，需要探究 “break point” $k$ 与 $m_\mathcal{H}(N)$ 之间的关系。回顾一下，$m_\mathcal{H}(N)$ 表示假设空间在 $N$ 个样本点上能产生的最大二分数量，$k$ 表示不能满足完全分类情形的样本点数。 让我们来探讨一下，当 $k$ 确定时，$m_\mathcal{H}(N)$ 的最大可能取值，下面使用一个例子来进行探讨。 Example: Break Point $k=2$根据 break point 的定义 当样本数为 $N=1$ 时，需要满足样本完全二分的情况，因此 $m_\mathcal{H}(1) = 2^1 = 2$ 当样本数为 $N=2$ 时，不可满足样本完全二分的情况，因此 $m_\mathcal{H}(2) &lt; 2^2 = 4$，最多为 $m_\mathcal{H}(2)=3$ 当样本数为 $N=3$ 时，同样不可满足样本完全二分的情况，因此 $m_\mathcal{H}(3) &lt; 2^3 = 8$，但是由于 $m_\mathcal{H}(2)$ 已经存在上限 $m_\mathcal{H}(2)&lt;4$，因此 $m_\mathcal{H}(3)$ 的值会有更严格的上限。根据实验可以得到 $m_\mathcal{H}(3) &lt; 5$。 $k=2$ 时 $m_\mathcal{H}(3) &lt; 5$ 的含义是：当样本数为 $N=3$ 时，假设空间最多有 $4$ 种分类结果，使得对任意 $k=2$ 个样本，不能满足完全分类的情形。 以上的分析比较晦涩难懂，我们使用图片重新说明一下。可以看到当只有 $1,2,3$ 种分类结果的时候，任意两个样本都不会出现完全分类的情形。当有 $4$ 种分类结果的时候，可能会出现有两个样本完全分类的情况，也可能不出现这种情况。而有 $5$ 种分类结果的时候，始终会出现有两个样本完全分类的情况。因此，二分类结果最多只能有 $4$ 种。 Bounding Function: Basic Cases我们将刚才讨论的东西起一个名字，叫做 bounding function $B(N,k)$，表示当 break point 为 $k$ 的时候，$m_\mathcal{H}(N)$ 的最大可能的值。 那么经过前面的例子，我们可以得到一些结论： $k=1$ 时，$B(N,k)=1$（任意一个点都不能被完全分类，因此只能有一种分类结果） $k&gt;N$ 时，$B(N,k)=2^N$（总共就 $N$ 个点，最多就 $2^N$ 种分类结果）； $k=N$ 时，$B(N,k)=2^N-1$（减去一种分类结果，则任意 $N$ 个点不会被完全分类）； $B(3,2)=4$（刚才的例子）； 于是我们得到了下面这个表格：$$\begin{array}{c|lcr}&amp;&amp;&amp;&amp;k\\B(N,k)&amp;1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;\cdots \\\hline1&amp;1&amp;2&amp;2&amp;2&amp;2&amp;2&amp;\cdots\\2&amp;1&amp;3&amp;4&amp;4&amp;4&amp;4&amp;\cdots\\3&amp;1&amp;4&amp;7&amp;8&amp;8&amp;8&amp;\cdots\\4&amp;1&amp;&amp;&amp;15&amp;16&amp;16&amp;\cdots\\5&amp;1&amp;&amp;&amp;&amp;31&amp;32&amp;\cdots\\6&amp;1&amp;&amp;&amp;&amp;&amp;63&amp;\cdots\\\vdots&amp;\vdots&amp;&amp;&amp;&amp;&amp;&amp;\ddots\end{array}$$ Bounding Function: Inductive Cases至此，我们已经解决了一半的问题。不过，表格里打问号的才是我们要讨论的重点，我们试着通过递推的方法得到这些值。 Dichotomies of $B(4,3)$我们用计算机列举出 $B(4,3)$ 的所有可能，同时将这些结果重新排列，如下图所示： 其中橙色的表示前 $3$ 个样本点成对出现，数量记为 $2\alpha$，绿色的表示前 $3$ 个样本点单独出现，数量记为 $\beta$，那么有 $B(4,3) = 2 \alpha + \beta$。 $B(4,3)$ 表示所有 $4$ 个样本点中，任意 $3$ 个都不会被完全分类。那么去掉第 $4$ 个样本，可以得到： $\alpha+\beta$ 中，前 $3$ 个样本点中的任意 $3$ 个不会被完全分类，$\alpha + \beta \le B(3,3)$； $\alpha$ 中，前 $3$ 个样本点中的任意 $2$ 个不会被完全分类，$\alpha \le B(3,2)$（因此第 $4$ 个点会被完全分类）； 因此：$$B(4,3) = 2\alpha+\beta=(\alpha+\beta)+\alpha\le B(3,3)+B(3,2)$$ 推广到其他：$$B(N,k)\le B(N-1,k)+B(N-1,k-1)$$ 数学归纳法可以证明：$$B(N,k) \leq \sum_{i=0}^{k-1} {N \choose i}$$ 因此可以得到，当 break point $k$ 存在时 $$m_\mathcal{H}(N) \le B(N,k) \leq \sum_{i=0}^{k-1} {N \choose i}$$ $m_\mathcal{H}(N)$ 是 $N$ 的多项式函数。 Mathematical Induction下面使用数学归纳法证明 $B(N,k) \le\sum_{i=0}^{k-1}{N \choose i}$ $k=1$ 时，不等式恒成立，因此只讨论 $k \ge 2$ 的情形； $N=1$ 时，不等式成立； 假设 $N=No$ 时，不等式成立，下面证明 $N=No+1$ 时，不等式成立。 $$\begin{aligned}B(N_{o}+1,k) &amp;\leq B(N_{o},k) + B(N_{o},k-1) \\\&amp;\leq \sum_{i=0}^{k-1}\binom{N_{o}}{i}+\sum_{i=0}^{k-2}\binom{N_{o}}{i} \\\&amp;=1+\sum_{i=1}^{k-1}\binom{N_{o}}{i}+\sum_{i=1}^{k-1}\binom{N_{o}}{i-1} \\\&amp;=1+\sum_{i=1}^{k-1}[\binom{N_{o}}{i}+\binom{N_{o}}{i-1}] \\\&amp;=1+\sum_{i=1}^{k-1}\binom{N_{o}+1}{i}=\sum_{i=0}^{k-1}\binom{N_{o}+1}{i}\end{aligned}$$ A Pictorial Proof于是利用有限的 $m_{\mathcal{H}}(N)$ 来替换无限的 $M$，得到 $\mathcal{H}$ 遇到Bad Sample的概率上界：$$\mathbb{P}_\mathcal{D}[BAD\ D]\leq 2m_{\mathcal{H}}(N)\cdot exp(-2\epsilon ^2N)$$ 用更加精准的数学符号来表示上面的不等式：$$\mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\gt \epsilon]\leq 2m_{\mathcal{H}}(N)\cdot exp(-2\epsilon ^2N)$$ 但事实上上面的不等式是不严谨的，因为 $m_{\mathcal{H}}(N)$ 描述的是 $\mathcal{H}$ 作用于数据量为 $N$ 的资料 $\mathcal{D}$ 有效的方程数，因此 $\mathcal{H}$ 当中每一个 $h$ 作用于 $\mathcal{D}$ 都能算出一个 $E_{in}$ 来，一共能有 $m_{\mathcal{H}}(N)$ 个不同的 $E_{in}$，是一个有限的数。但在out of sample的世界里(总体)，往往存在无限多个点，平面中任意一条直线，随便转一转动一动，就能产生一个不同的 $E_{out}$ 来。$E_{in}$ 的可能取值是有限个的，而 $E_{out}$ 的可能取值是无限的，无法直接套用union bound，我们得先把上面那个无限多种可能的 $E_{out}$ 换掉。 下面涉及到许多数学公式，先挖个坑，有时间补上。]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-为什么机器能够学习(1)]]></title>
    <url>%2F20180311-NTU-ML-4%2F</url>
    <content type="text"><![CDATA[接着上一篇所讨论的问题，继续讨论。 Recap and Preview回顾一下机器学习的流程图： 机器学习可以理解为寻找到 $g$，使得 $g \approx f$，也就是 $E_{out}(g) \approx 0$ 的过程。为了完成这件事情，有两个关键的步骤： 保证 $E_{out}(g) \approx E_{in}(g)$，由 “训练” 过程来完成 保证 $E_{in}(g) \approx 0$，由 “验证” 过程来完成 当这两件事情都得到保证之后，我们就可以得到 $E_{out}(g) \approx 0$，于是完成了学习。 $M$ 的取值（hypothesis 的数目）会影响上面说的两个步骤： $M$ 太小，能保证 $E_{out}(g) \approx E_{in}(g)$，但是不能保证 $E_{in}(g) \approx 0$（因为可选择的 hypothesis 的数目太少）； $M$ 太大，能保证 $E_{in}(g) \approx 0$，但是不能保证 $E_{out}(g) \approx E_{in}(g)$$\big(\begin{split}\Bbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}]\le2M\exp(-2\epsilon^2N)\end{split}\big)$。 因此需要想办法解决 $M$ 较大时，$E_{out}(g) \approx E_{in}(g)$ 的问题。 Effective Number of Lines由上一篇文章我们知道：$$\Bbb{P} \Big[\Big| E_{in}(g) - E_{out}(g) \Big| &gt; \epsilon\Big] \le 2M \exp(-2 \epsilon^2 N)$$ 对于这个式子，$M = \infty$ 时，右侧的值很大，$E_{out}(g) \approx E_{in}(g)$ 不能保证。我们的想法是：尝试用一个合适的数 $m_H$ 代替式子中的 $M$，使无穷变成有限，如下式：$$\Bbb{P} \Big[\Big| E_{in}(g) - E_{out}(g) \Big| &gt; \epsilon\Big] \stackrel{?}{\le} 2 \cdot m_{\mathcal{H}} \cdot \exp(-2 \epsilon^2 N)$$ 第一个式子中的 $M$ 来源于 “Union Bound”$$\Bbb{P} [ \mathcal{B}_{1} \hphantom{1} or \hphantom{1} \mathcal{B}_{2} \hphantom{1} or \dots \mathcal{B}_{M} ] \le \Bbb{P} [ \mathcal{B}_{1}] + \Bbb{P} [ \mathcal{B}_{2}] + \dots + \Bbb{P} [ \mathcal{B}_{M}]$$ 其中 $\Bbb{P}[\mathcal{B}_{M}]$ 表示的是第 $M$ 个假设函数 $h_M$ 在数据集上发生坏事情（即存在 BAD DATA，$E_{out}(h_M) \neq E_{in}(h_M)$）的概率。 然而当 $M$ 很大时，假设集中存在许多相似的假设函数 $h$，它们发生坏事情的概率和情形都很接近，这样使用 “Union Bound” 来计算整个假设集发生坏事情的概率，便存在许多重复的地方，于是算出来的概率会比实际的高很多（over-estimating）。 我们换一种思路，从数据点的分类结果来对假设集进行分类，这样就避免了假设之间相互重合的问题。以二元分类来阐述怎么解决这个问题：我们根据分类结果，对 $h$ 进行分类。 样本点大小 $N$ 假设集 $H$ 等价类（考虑最多的情况） 1 2 类：$\{o\}$、$\{x\}$ 2 4 类：$\{oo\}$、$\{ox\}$、$\{xo\}$、$\{xx\}$ … … N $2^{N} 类$ 对于一个大小为 $N$ 的数据集，任意一个假设函数 $h$ 都属于上述 $2^N$ 个等价类之间的一个，因此我们可以用 $2^N$ 来代替原不等式中的 $M$。 Effective Number of Hypotheses我们把上面提到的等价类的概念起一个名字叫做 Dichotomy。 具体的 Dichotomy 的 size 与这 $N$ 个数据的具体取值有关（但是不会大于 $2^N$），为方便讨论我们取最大那个 size 来分析，取名为 growth function，记作 $m_\mathcal{H}(N)$，意思是假设空间在 $N$ 个样本点上能产生的最大二分数量。$$m_\mathcal{H}(N) = \max \limits_{\textbf{x}_1,\textbf{x}_2,…,\textbf{x}_N \in \mathcal{X}} \big| \mathcal{H}(\textbf{x}_1,\textbf{x}_2,…,\textbf{x}_N) \big|$$接下来我们需要计算 $m_\mathcal{H}(N)$，首先考虑几种不同的模型的 $m_\mathcal{H}(N)$ Positive Rays确定一个点，规定在这个点的正方向为正，即 $h(x)=+1$，反方向为负，即 $h(x)=-1$。在这种情况下 $m_\mathcal{H}(N) = N + 1$，如下图所示。 Positive Intervals确定两个点，规定在这两个点之间为正，即 $h(x)=+1$，两个点之外为负，即 $h(x)=-1$。在这种情况下 $m_\mathcal{H}(N) = {N+1 \choose 2} + 1$，如下图所示。 Convex Sets顶点在同一个圆上的凸多边形，规定圆上与多边形相交的点为正，即 $h(x)=+1$，没有与多边形相交的点为负，即 $h(x)=-1$。在这种情况下 $m_\mathcal{H}(N) = 2^N$，如下图所示。 2D perceptrons就是前面举的平面上的点分类的例子，某些情况下 $m_\mathcal{H}(N) &lt; 2^N$。 将上面几种情况总结如下： model $m_\mathcal{H}(N)$ Positive Rays $m_\mathcal{H}(N) = N + 1$ Positive Intervals $m_\mathcal{H}(N) = {N+1 \choose 2} + 1$ Convex Sets $m_\mathcal{H}(N) = 2^N$ 2D perceptrons $m_\mathcal{H}(N) &lt; 2^N$ in some case Break Point我们希望 $m_H(N)$ 是多项式形式而不是指数形式的，这样当 $N$ 很大的时候，不等式右边趋近于0，才能保证 $E_{out}(g) \approx E_{in}(g)$：$$\Bbb{P} \Big[\Big| E_{in}(g) - E_{out}(g) \Big| &gt; \epsilon\Big] \stackrel{?}{\le} 2 \cdot m_{\mathcal{H}} \cdot \exp(-2 \epsilon^2 N)$$ 因此，将 $m_{\mathcal{H}}$ 替换为 $2^N$ 还不够，为此我们引入一个概念叫 break point，定义如下 if no $k$ inputs can be shattered by $\mathcal{H}$, call $k$ a break point for $\mathcal{H}$ $m_{\mathcal{H}}(k) &lt; 2^{k}$ $k+1$, $k+2$, $k+3$, $…$ also break points will study minimum break point $k$ 对应的，上面所提到的四种模型的 break point 如下： model $m_\mathcal{H}(N)$ break point Positive Rays $m_\mathcal{H}(N) = N + 1$ break point at 2 Positive Intervals $m_\mathcal{H}(N) = {N+1 \choose 2} + 1$ break point at 3 Convex Sets $m_\mathcal{H}(N) = 2^N$ no break point 2D perceptrons $m_\mathcal{H}(N) &lt; 2^N$ in some case break point at 4 我们猜测 $m_\mathcal{H}(N)$ 与 break point 有下面的关系： no break point：$m_\mathcal{H}(N) = 2^N$ break point $k$：$m_\mathcal{H}(N) = O(N^{k-1})$ 如果猜测成立，那么在有 break point 的情况下，$m_H(N)$ 便是一个多项式形式，这样就能保证 $E_{out}(g) \approx E_{in}(g)$ 了。 因此，接下来我们需要探讨，break point 与 $m_\mathcal{H}(N)$ 之间的关系，我们将在下几篇文章中对此进行讨论。]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-学习的可行性]]></title>
    <url>%2F20180118-NTU-ML-3%2F</url>
    <content type="text"><![CDATA[在这篇文章中，我们主要探讨，机器到底能不能进行学习这个问题。 Learning is Impossible?从前面的文章中，我们已经知道，机器学习的过程，就是通过现有的训练集 $D$ 学习，得到预测函数 $h$，并且使得它接近于目标函数 $f$。 我们必须思考的问题是：这种预测是可能的么？也就是说，机器能通过学习得到 $h$，使得 $h \approx f$ 吗？ No free lunch机器学习领域有一个著名的理论，叫做 “没有免费的午餐” 定理（No Free Lunch Theorem, 简称 NFL 定理）。用比较通俗易懂的话来讲，意思就是说：“学习” 可能是做不到的。 在训练样本集（in-sample）中，可以求得一个最佳的假设 $g$，该假设最大可能的接近目标函数 $f$，但是在训练样本集之外的其他样本（out-of-sample）中，假设 $g$ 和目标函数 $f$ 可能差别很远。 Example我们举一个例子来说明上面这段话的意思。现在假设有这样一个数据集 $X=\{000,001,…,111\}$ 总共8个数据，使用函数 $f$ 对数据集中的每一个数据分类（圈或叉）。现在我们手头有5个训练样本，我们想让机器使用这些训练样本学习到函数$f$。 由于机器只能看到训练集的样本（5个），因此它能学习得到函数 $g$，使得在这些训练样本上，$g$ 与 $f$ 的预测结果一样。 但是，因为机器看不见训练集外的样本（剩下的3个），对于这些样本，机器只能自己猜测$g(x)$的值。而无论机器预测的结果是怎么样的，我们总能够找到$f$，使得在这些训练集外的样本上，$g \neq f$。 Summary从上面的例子我们可以看出，机器能学习的，只是它看得见的样本（in-sample），而对于它看不见的样本（out-of-sample），学习效果就很难保证了。 如果是这样子的话，机器学习的作用的很有限了，毕竟我们更需要的，是机器机帮我们处理没见过的数据。 嗯，事情一定没这么简单。 Probability to the Rescue我们想象这样一个场景：有一个罐子，这个罐子里装有橙色和绿色两种颜色的珠子，我们如何在不查遍所有珠子的情况下，得知罐子中橙子珠子所占的比例呢？一个想法就是使用抽样的方法，通过频率来预测概率。 假设罐子中橙色珠子的概率为 $\mu$（未知），则绿色珠子的概率为 $1-\mu$；假设通过抽样查出的橙色珠子比例为 $v$（已知），则绿色珠子的比例为 $1-v$。那么我们可不可以通过 $v$ 来预测 $\mu$ 呢？ Hoeffding’s inequality数学上有个霍夫丁不等式，专门回答了这个问题。这个不等式是这样子的： 当样本数量 $N$ 足够大时，$v$ 和 $\mu$ 有如下关系：$$\Bbb{P}[\left|\nu-\mu\right|\gt\epsilon]\le2\exp\big(-2\epsilon^2N\big)$$ 从上面的式子可以看出，随着样本数量 $N$ 的逐渐增大，$v$ 与 $\mu$ 接近的概率也逐渐增大，因此可以说 $v$ 与 $\mu$ 大概近似相等（probably approximately correct，PAC），因此，选择合适的 $N$ 以及 $\epsilon$，就可以通过 $v$ 预测 $\mu$。 Connection to Learning我们可以将以上的情景与机器学习问题对应起来，如下图所示： 相对应的概念如下所示： 罐子：数据集，包括 in-sample 以及 out-of-sample 橙色珠子：数据 $x_n$, 其中 $h(x_n) \neq f(x_n)$ 绿色珠子：数据 $x_n$, 其中 $h(x_n) = f(x_n)$ 橙色珠子概率 $\mu$：$h(x) \neq f(x)$ 的概率 抽到的珠子：训练样本（我们看得到的那些） 抽到橙色珠子：在某个样本点 $x_n$ 上，$h(x_n) \neq f(x_n) = y_n$ 抽到绿色珠子：在某个样本点 $x_n$ 上，$h(x_n) = f(x_n) = y_n$ 橙色珠子频率 $v$：$h(x) \neq f(x)$ 的频率 抽样动作：判断 $h(x_n)$ 与 $f(x_n)=y_n$ 是否相等 于是在样本数足够多的情况下，我们可以通过测试 $h(x_n) \neq y_n$ 的频率来推断 $h(x) \neq f(x)$ 的概率。这里需要注意的是，$x_n$ 需要是独立同分布的，但是我们并不需要知道具体的分布函数是什么。 Learning Flow我们对学习流程图进行完善，如下图所示： 我们在流程图中增加了一个数据的分布函数 $P$，我们并不知道这个分布具体的样子（但是没关系），我们利用这个分布进行抽样，产生训练样本，同时利用这些训练样本，计算 $h(x) \neq f(x)$ 的频率 $E_{in}(h)$，并且使用这个频率来估计 $h(x) \neq f(x)$ 的概率 $E_{out}(h)$。这里所说的 $h$，是我们从假设集 (hypothesis set) 中选择的一个特定的 $h$。 The Formal Guarantee将霍夫丁不等式中的 $\mu$ 换成 $E_{out}(h)$，$v$ 换成 $E_{in}(h)$，就可以得到下面的式子： $$\Bbb{P}\left[\left|E_{in}(h)-E_{out}(h)\right|\gt\epsilon\right]\le2\exp\big(-2\epsilon^2N\big)$$ 上面的公式保证了在一定条件下，$E_{in}(h)$ 与 $E_{out}(h)$ 不会相差太远，那么只要我们能选择合适的 $h$ 使得 $E_{in}(h)$ 比较小，那么 $E_{out}(h)$ 也会比较小。 Verification of One $h$整理一下，对于一个固定的 $h$，霍夫丁不等式告诉我们，在样本数足够多的情况下，如果 $E_{in}(h)$ 很小，那么 $E_{out}(h)$ 也会大概率比较小。 机器学习要做的事，是通过算法 $\mathcal{A}$ 从假设集 $H$ 中选择 $g$，使得 $g$ 尽可能接近 $f$。换句话来讲，需要在假设集 $H$ 中找到一个 $h$，使得 $E_{in}(h)$ 很小，然后把 $h$ 当成最终的预测函数 $g$。 我们现在做的事情，因为只涉及了一个 $h$，准确来讲不是 “学习”，而是 “验证”，即对于一个 $h$，通过 $E_{in}(h)$ 估计 $E_{out}(h)$。 我们还需要探讨，如果算法是在多个 $h$ 中进行选择（而不是只有一个 $h$，不需要选择），那么情况有什么变化。也就是从探讨 $E_{in}(h)$ 与 $E_{out}(h)$ 的关系，变成探讨 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系。 Connection to Real Learning首先我们考虑假设集中的假设是有限多个的情况。 来看一下下面这个表格，表格中的每一行表示一个固定的 $h$ 的情况，表格中的每一列表示一笔数据集，表格里的 “BAD” 表示，在这笔数据集上，对于某个特定的 $h$，$E_{in}(h)$ 与 $E_{out}(h)$ 相差很大，我们把这样的数据叫做是这个 $h$ 上的 BAD data。 霍夫丁不等式告诉我们，对于一个固定的$h$，出现 $E_{in}(h)$ 与 $E_{out}(h)$ 相差很大的概率很小，也就是说，对于表格中的每一行， BAD data 出现的概率很小，在这样的情况下，我们才能通过 $E_{in}$ 来预测 $E_{out}$。$$\Bbb{P}\big[ \big| E_{in}(h) - E_{out}(h) \big| &gt; \epsilon \big] \le 2 \exp \big( -2 \epsilon^2 N \big)$$同样的，当有多个 $h$ 可选择时，我们也希望 BAD data 出现的概率小，这样才能让算法在假设集中自由选择 $h$，保证能通过$E_{in}$ 来预测 $E_{out}$。 这种情况下，只要数据对于某个 $h$ 而言是 BAD data，它在这个假设集中就是 BAD data，其出现的概率为：$$\begin{split}\Bbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}]&amp;=\Bbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_1\ or\ BAD\ \mathcal{D}\ for\ h_2\ or\ …\ or\ BAD\ \mathcal{D}\ for\ h_M]\\&amp;\le\Bbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_1]+ \Bbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_2]+ …+\Bbb{P}_{\mathcal{D}}[BAD\ \mathcal{D}\ for\ h_M]\\&amp;\le2\exp\big(-2\epsilon^2N\big)+\exp\big(-2\epsilon^2N\big)+\exp\big(-2\epsilon^2N\big)+…+\exp\big(-2\epsilon^2N\big)\\&amp;=2M\exp\big(-2\epsilon^2N\big)\end{split}$$其中 $M$ 表示的是假设集中 $h$ 的个数。 因此得到结论：如果 $M$ 的值是有限的，在 $N$ 足够大的情况下，BAD data 出现的概率很小，即无论哪个 $h$，都有 $E_{in}(h) \approx E_{out}(h)$ （PAC），那么我们通过合适的算法选择一个 $E_{in}$ 小的 $h$，就能保证 $E_{out}$ 小（PAC），于是学习成功了。 最后完善学习流程图： 以上，我们讨论了假设集中的假设是有限多个的情况下，$E_{in}(g)$ 与 $E_{out}(g)$ 的关系。关于假设集中的假设是无限多个的情况，将在接下来的文章中讨论。]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-感知器算法]]></title>
    <url>%2F20180115-NTU-ML-2%2F</url>
    <content type="text"><![CDATA[这节课主要介绍感知器算法（Perceptron Learning Algorithm）。 Perceptron Hypothesis Set对于一个线性可分的二分类问题，我们可以采用感知器 （Perceptron）这种假设集。 采用这种假设集进行分类的思想是这样的：我们假设样本的类别是由样本每一个特征 $\textbf{x}_i$ 共同决定，其中不同的特征的重要程度不一样。于是我们通过对所有的特征进行加权 $\sum_{i=1}^d \textbf{w}_i \textbf{x}_i$，得到一个“分数”，将这个“分数”与一个阈值 $threshold$ 进行比较，如果“分数”大于阈值，那么这个样本属于一个类别（类别“+1”），如果“分数”小于阈值，那么这个样本属于另一个类别（类别“-1”）。 这种模型可以用下面的表达式表示出来：$$\begin{split}h(\textbf{x})&amp;= sign \Bigg( \Big( \sum_{i=1}^d \textbf{w}_i \textbf{x}_i \Big) - threshold \Bigg) \ \ \ \ h\in \mathcal{H} \\&amp;= sign \Bigg( \Big( \sum_{i=1}^d \textbf{w}_i \textbf{x}_i \Big) + \Big(- threshold \Big) \cdot \Big( +1 \Big) \Bigg) \\&amp;= sign \Big( \sum_{i=0}^d \textbf{w}_i \textbf{x}_i \Big) \\&amp;= sign \Big( \textbf{w}^T \textbf{x} \Big)\end{split}$$ 其中不同的向量 $\textbf{w}$ 代表了不同的假设函数 $h(\textbf{x})$，我们的目标是使用一些算法调整 $w$ 的值，使得假设函数 $h(\textbf{x})$ 与我们要预测的函数 $f(\textbf{x})$ 尽可能的接近。 我们的想法是：如果 $h(\textbf{x})$ 与 $f(\textbf{x})$ 足够接近，那么它们作用在训练集 $D$ 上的结果会是一样的，即对训练集中的 $\textbf{x}$，有 $f(\textbf{x}) = h(\textbf{x})$。反过来说，如果对所有训练集中的 $\textbf{x}$，有 $f(\textbf{x}) = h(\textbf{x})$，那么在一定程度上，我们可以认为 $h(\textbf{x})$ 与 $f(\textbf{x})$ 是接近的。 Perceptron Learning Algorithm (PLA)这个模型中训练 $\textbf{w}$ 的算法称为感知器算法（Perceptron Learning Algorithm），算法的思想是（尽可能地）对预测错误的样本进行修正，使得分类器的预测结果越来越好。预测错误的样本可以分为以下两种类型： 当 $f(\textbf{x})=y=+1$ 而预测结果 $h(\textbf{x})=sign(\textbf{w}^T\textbf{x})=-1$ 时，说明此时 $\textbf{w}$ 与 $\textbf{x}$ 的内积过小，夹角过大，需要让 $\textbf{w}$ 靠近 $\textbf{x}$，因此将 $\textbf{w}$ 改为 $\textbf{w}+\textbf{x}=\textbf{w}+y\textbf{x}$; 当 $f(\textbf{x})=y=-1$ 而预测结果 $h(\textbf{x})=sign(\textbf{w}^T\textbf{x})=+1$ 时，说明此时 $\textbf{w}$ 与 $\textbf{x}$ 的内积过大，夹角过小，需要让 $\textbf{w}$ 远离 $\textbf{x}$，因此将 $\textbf{w}$ 改为 $\textbf{w}-\textbf{x}=\textbf{w}+y\textbf{x}$; 反复修正预测错误的样本点直到所有训练样本都预测正确，选择预测错误的样本的顺序没有限制，可以按自然顺序，也可以随机选择。 算法描述如下图： 例子我们举一个例子来说明 PLA 算法的过程。 Guarantee of PLA目前我们还有一些问题没有讨论，其中比较重要的一个问题是，PLA是不是收敛的，即算法最终能不能停止下来。 首先我们讨论线性可分的情况，线性不可分的情况在下一节中讨论。当数据集是线性可分时，表示存在 $\textbf{w}_f$ 使得 $y_n = sign(\textbf{w}_f^T \textbf{x}_n)$，下面证明PLA是收敛的，即 $\textbf{w}$ 能收敛到 $\textbf{w}_f$，即算法能停止下来。 $\textbf{w}_f$ 与 $\textbf{w}_t$ 的内积会单调递增 $\textbf{w}_t$ 的长度有限制 以上两点可以推出：当算法从 $\textbf{w}_0 = 0$ 开始时，算法更新次数 $T \leq \frac{R^2}{\rho^2}$其中 $$R^2 = \max \limits_{n}\{f(\textbf{x})\}$$$$ \quad \rho = \min \limits_{n} y_n \frac{\textbf{w}_f^T}{||\textbf{w}_f^T||} \textbf{x}_n$$因此说明了算法最终会收敛。 总结我们对PLA进行一下总结： 收敛性在数据是线性可分的条件下，算法能收敛。 算法的优点算法容易简单、实现；算法速度快；在任意维度下都能工作。 算法的缺点需要数据是线性可分的条件；不知道算法什么时候收敛。 Non-Separable Data当数据集是线性不可分时，表示数据中有噪声（这里的噪声是相对于感知器这个假设集而言的）。在这种情况下，学习的过程发生了一点改变： 对感知器模型来说，此时可能无法使所有样本都正确分类，此时我们应该退而求其次，找尽可能犯错少的分界面，我们的学习的目标从$$ \arg \limits_{ \textbf{w} } y_n = sign( \textbf{w}^T \textbf{x}_n) $$ 变成了$$ \arg \min \limits_{w} \sum {[[y_n \neq sign(w^Tx_n)]]}$$不幸的是，这是一个 NP-hard 问题。 此时的一种思路是使用贪心算法，于是PLA可以改进成Pocket算法：]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-机器学习问题]]></title>
    <url>%2F20180113-NTU-ML-1%2F</url>
    <content type="text"><![CDATA[IntrodctionWhat is Machine Learning 机器学习：计算机通过数据和计算获得一定技巧的过程。 技巧：指的是在某些事情上表现更加出色，比如预测、识别等等。 Why using Machine Learning 一些数据或者信息，人来无法获取，可能是一些人无法识别的事物，或是数据信息量特别大； 人的处理满足不了需求，比如：定义很多很多的规则满足物体识别或者其他需求；在短时间内通过大量信息做出判断等等。 When to use Machine Learning 存在一个模式或者说表现可以让我们对它进行改进提高； 规则并不容易那么定义； 需要有数据。 Components of Machine Learning一个机器学习问题，主要由以下几部分构成： 输入： $\textbf{x} \in \mathcal{X}$ 输出： $\textbf{y} \in \mathcal{Y}$ 目标函数：$f: \mathcal{X} \rightarrow \mathcal{Y}$ 数据：$\mathcal{D} = \{ (\textbf{x}_1, \textbf{y}_1), (\textbf{x}_2, \textbf{y}_2) \ldots (\textbf{x}_N, \textbf{y}_N),\}$ 假设：$g: \mathcal{X} \rightarrow \mathcal{Y}$ 目标函数 $f: \mathcal{X} \rightarrow \mathcal{Y}$ 将输入 $\mathcal{X}$ 映射为输出 $\mathcal{Y}$，我们手头有一组由 $f$ 生成的数据 $\mathcal{D}$，目标就是通过对数据的学习，得到一个假设 $g: \mathcal{X} \rightarrow \mathcal{Y}$，使得 $g$ 与 $f$ 尽量接近。 Learning Flow以一个更加详细的流程图来说明这一过程： 目标函数 $f: \mathcal{X} \rightarrow \mathcal{Y}$ 将输入 $\mathcal{X}$ 映射为输出 $\mathcal{Y}$，$\mathcal{X}$ 与 $\mathcal{Y}$ 在一起构成了数据 $\mathcal{D}$，我们的目标就是通过对数据的学习，得到一个假设 $g: \mathcal{X} \rightarrow \mathcal{Y}$，使得 $g$ 与 $f$ 尽量接近。为此，我们必须选定一个假设空间 $\mathcal{H}$，然后使用算法 $\mathcal{A}$，选择 $\mathcal{H}$ 里的一个假设作为 $g$。 在这里有几个需要注意的地方： 机器学习的输入在这个流程图中就变成了两个部分，一个是训练样本集，而另一个就是假设空间 $\mathcal{H}$。 我们所说的机器学习模型在这个流程图中也不仅仅是算法 $\mathcal{A}$，而且还包含了假设空间 $\mathcal{H}$。 上图还是一个相对比较简单的机器学习流程图，在往后的文章中会不断的根据新学的知识继续扩展这幅图的元素。 Types of LearningLearning with Different Output Space $\mathcal{Y}$按照数据的输出，可以把 ML 分为以下几类： 二类别分类问题：$\mathcal{Y} \in \{0, 1\}$ 多类别分类问题：$\mathcal{Y} \in \{0, 1, \cdots, K\}$ 回归问题：$\mathcal{Y} \in R$ 结构学习 Learning with Different Data Label $y_n$按照数据的标签，可以把 ML 分为以下几类： supervised： 所有 $x_n$ 都具有 $y_n$ unsupervised： 所有 $x_n$ 都没有 $y_n$ semi-supervised： 一些 $x_n$ 具有 $y_n$ Learning with Different Protocol $f$按照数据的传输方式，可以把 ML 分为以下几类： batch： 一次性把所有的数据给算法 online： 连续的数据，一次处理一个数据 active： 机器通过主动询问某些问题来学习 Learning with Different Input Space $\mathcal{X}$按照数据的输入，可以把 ML 分为以下几类： concrete： 精细的、复杂的、有序的，已经完成预处理的数据 raw： 原始的，未经处理或者经过很少处理的数据 abstract：抽象的，无法轻易表明含义的数据]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-《机器学习基石》笔记系列]]></title>
    <url>%2F20180113-NTU-ML-0%2F</url>
    <content type="text"><![CDATA[前言“机器学习基石”是 Coursera 上一门关于机器学习的课程，由国立台湾大学的老师林轩田讲授。该课程一共有16节课，主要介绍了机器学习领域的基础理论知识。 授课大纲课程的大纲如下，以下的每个小项目对应到约一小时的课程： When Can Machines Learn? [何时可以使用机器学习]– The Learning Problem [机器学习问题]– Learning to Answer Yes/No [二元分类]– Types of Learning [各式机器学习问题]– Feasibility of Learning [机器学习的可行性] Why Can Machines Learn? [为什么机器可以学习]– Training versus Testing [训练与测试]– Theory of Generalization [举一反三的一般化理论]– The VC Dimension [VC 维度]– Noise and Error [噪声时错误] How Can Machines Learn? [机器可以怎么样学习]– Linear Regression [线性回归]– Linear Soft Classification [软性的线性分类]– Linear Classification beyond Yes/No [二元分类以外的分类问题]– Nonlinear Transformation [非线性转换] How Can Machines Learn Better? [机器可以怎么样学得更好]– Hazard of Overfitting [过度训练的危险]– Preventing Overfitting I: Regularization [避免过度训练一：控制调适]– Preventing Overfitting II: Validation [避免过度训练二：自我检测]– Three Learning Principles [三个机器学习的重要原则] 计划我将把课程按照自己的理解，整理成一份通俗易懂的笔记，一方面记录所学知识，另一方面与大家一起分享，共同进步。 点击右侧可关注我的 github 地址。 笔记链接NTU-ML-机器学习问题NTU-ML-感知器算法]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
</search>
