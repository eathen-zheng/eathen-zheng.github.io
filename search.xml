<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[NTU-ML-感知器算法]]></title>
    <url>%2F20180115-NTU-ML-2%2F</url>
    <content type="text"><![CDATA[这节课主要介绍感知器算法（Perceptron Learning Algorithm）。 Perceptron Hypothesis Set对于一个线性可分的二分类问题，我们可以采用感知器 （Perceptron）这种假设集。 采用这种假设集进行分类的思想是这样的：我们假设样本的类别是由样本每一个特征 $\textbf{x}_i$ 共同决定，其中不同的特征的重要程度不一样。于是我们通过对所有的特征进行加权 $\sum_{i=1}^d \textbf{w}_i \textbf{x}_i$，得到一个“分数”，将这个“分数”与一个阈值 $threshold$ 进行比较，如果“分数”大于阈值，那么这个样本属于一个类别（类别“+1”），如果“分数”小于阈值，那么这个样本属于另一个类别（类别“-1”）。 这种模型可以用下面的表达式表示出来：$$\begin{split}h(\textbf{x})&amp;= sign \Bigg( \Big( \sum_{i=1}^d \textbf{w}_i \textbf{x}_i \Big) - threshold \Bigg) \ \ \ \ h\in \mathcal{H} \\&amp;= sign \Bigg( \Big( \sum_{i=1}^d \textbf{w}_i \textbf{x}_i \Big) + \Big(- threshold \Big) \cdot \Big( +1 \Big) \Bigg) \\&amp;= sign \Big( \sum_{i=0}^d \textbf{w}_i \textbf{x}_i \Big) \\&amp;= sign \Big( \textbf{w}^T \textbf{x} \Big)\end{split}$$ 其中不同的向量 $\textbf{w}$ 代表了不同的假设函数 $h(\textbf{x})$，我们的目标是使用一些算法调整 $w$ 的值，使得假设函数 $h(\textbf{x})$ 与我们要预测的函数 $f(\textbf{x})$ 尽可能的接近。 我们的想法是：如果 $h(\textbf{x})$ 与 $f(\textbf{x})$ 足够接近，那么它们作用在训练集 $D$ 上的结果会是一样的，即对训练集中的 $\textbf{x}$，有 $f(\textbf{x}) = h(\textbf{x})$。反过来说，如果对所有训练集中的 $\textbf{x}$，有 $f(\textbf{x}) = h(\textbf{x})$，那么在一定程度上，我们可以认为 $h(\textbf{x})$ 与 $f(\textbf{x})$ 是接近的。 Perceptron Learning Algorithm (PLA)这个模型中训练 $\textbf{w}$ 的算法称为感知器算法（Perceptron Learning Algorithm），算法的思想是（尽可能地）对预测错误的样本进行修正，使得分类器的预测结果越来越好。预测错误的样本可以分为以下两种类型： 当 $f(\textbf{x})=y=+1$ 而预测结果 $h(\textbf{x})=sign(\textbf{w}^T\textbf{x})=-1$ 时，说明此时 $\textbf{w}$ 与 $\textbf{x}$ 的内积过小，夹角过大，需要让 $\textbf{w}$ 靠近 $\textbf{x}$，因此将 $\textbf{w}$ 改为 $\textbf{w}+\textbf{x}=\textbf{w}+y\textbf{x}$; 当 $f(\textbf{x})=y=-1$ 而预测结果 $h(\textbf{x})=sign(\textbf{w}^T\textbf{x})=+1$ 时，说明此时 $\textbf{w}$ 与 $\textbf{x}$ 的内积过大，夹角过小，需要让 $\textbf{w}$ 远离 $\textbf{x}$，因此将 $\textbf{w}$ 改为 $\textbf{w}-\textbf{x}=\textbf{w}+y\textbf{x}$; 反复修正预测错误的样本点直到所有训练样本都预测正确，选择预测错误的样本的顺序没有限制，可以按自然顺序，也可以随机选择。 算法描述如下图： 例子我们举一个例子来说明 PLA 算法的过程。 Guarantee of PLA目前我们还有一些问题没有讨论，其中比较重要的一个问题是，PLA是不是收敛的，即算法最终能不能停止下来。 首先我们讨论线性可分的情况，线性不可分的情况在下一节中讨论。当数据集是线性可分时，表示存在 $\textbf{w}_f$ 使得 $y_n = sign(\textbf{w}_f^T \textbf{x}_n)$，下面证明PLA是收敛的，即 $\textbf{w}$ 能收敛到 $\textbf{w}_f$，即算法能停止下来。 $\textbf{w}_f$ 与 $\textbf{w}_t$ 的内积会单调递增 $\textbf{w}_t$ 的长度有限制 以上两点可以推出：当算法从 $\textbf{w}_0 = 0$ 开始时，算法更新次数 $T \leq \frac{R^2}{\rho^2}$其中 $$R^2 = \max \limits_{n}\{f(\textbf{x})\}$$$$ \quad \rho = \min \limits_{n} y_n \frac{\textbf{w}_f^T}{||\textbf{w}_f^T||} \textbf{x}_n$$因此说明了算法最终会收敛。 我们对PLA进行一下总结： 收敛性在数据是线性可分的条件下，算法能收敛。 算法的优点算法容易简单、实现；算法速度快；在任意维度下都能工作。 算法的缺点需要数据是线性可分的条件；不知道算法什么时候收敛。 Non-Separable Data当数据集是线性不可分时，表示数据中有噪声（这里的噪声是相对于感知器这个假设集而言的）。在这种情况下，学习的过程发生了一点改变： 对感知器模型来说，此时可能无法使所有样本都正确分类，此时我们应该退而求其次，找尽可能犯错少的分界面，我们的学习的目标从$$ \arg \limits_{ \textbf{w} } y_n = sign( \textbf{w}^T \textbf{x}_n) $$ 变成了$$ \arg \min \limits_{w} \sum {[[y_n \neq sign(w^Tx_n)]]}$$不幸的是，这是一个 NP-hard 问题。 此时的一种思路是使用贪心算法，于是PLA可以改进成Pocket算法：]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-机器学习问题]]></title>
    <url>%2F20180113-NTU-ML-1%2F</url>
    <content type="text"><![CDATA[IntrodctionWhat is Machine Learning 机器学习：计算机通过数据和计算获得一定技巧的过程。 技巧：指的是在某些事情上表现更加出色，比如预测、识别等等。 Why using Machine Learning 一些数据或者信息，人来无法获取，可能是一些人无法识别的事物，或是数据信息量特别大； 人的处理满足不了需求，比如：定义很多很多的规则满足物体识别或者其他需求；在短时间内通过大量信息做出判断等等。 When to use Machine Learning 存在一个模式或者说表现可以让我们对它进行改进提高； 规则并不容易那么定义； 需要有数据。 Components of Machine Learning一个机器学习问题，主要由以下几部分构成： 输入： $\textbf{x} \in \mathcal{X}$ 输出： $\textbf{y} \in \mathcal{Y}$ 目标函数：$f: \mathcal{X} \rightarrow \mathcal{Y}$ 数据：$\mathcal{D} = \{ (\textbf{x}_1, \textbf{y}_1), (\textbf{x}_2, \textbf{y}_2) \ldots (\textbf{x}_N, \textbf{y}_N),\}$ 假设：$g: \mathcal{X} \rightarrow \mathcal{Y}$ 目标函数 $f: \mathcal{X} \rightarrow \mathcal{Y}$ 将输入 $\mathcal{X}$ 映射为输出 $\mathcal{Y}$，我们手头有一组由 $f$ 生成的数据 $\mathcal{D}$，目标就是通过对数据的学习，得到一个假设 $g: \mathcal{X} \rightarrow \mathcal{Y}$，使得 $g$ 与 $f$ 尽量接近。 Learning Flow以一个更加详细的流程图来说明这一过程： 目标函数 $f: \mathcal{X} \rightarrow \mathcal{Y}$ 将输入 $\mathcal{X}$ 映射为输出 $\mathcal{Y}$，$\mathcal{X}$ 与 $\mathcal{Y}$ 在一起构成了数据 $\mathcal{D}$，我们的目标就是通过对数据的学习，得到一个假设 $g: \mathcal{X} \rightarrow \mathcal{Y}$，使得 $g$ 与 $f$ 尽量接近。为此，我们必须选定一个假设空间 $\mathcal{H}$，然后使用算法 $\mathcal{A}$，选择 $\mathcal{H}$ 里的一个假设作为 $g$。 在这里有几个需要注意的地方： 机器学习的输入在这个流程图中就变成了两个部分，一个是训练样本集，而另一个就是假设空间 $\mathcal{H}$。 我们所说的机器学习模型在这个流程图中也不仅仅是算法 $\mathcal{A}$，而且还包含了假设空间 $\mathcal{H}$。 上图还是一个相对比较简单的机器学习流程图，在往后的文章中会不断的根据新学的知识继续扩展这幅图的元素。 Types of LearningLearning with Different Output Space $\mathcal{Y}$按照数据的输出，可以把 ML 分为以下几类： 二类别分类问题：$\mathcal{Y} \in \{0, 1\}$ 多类别分类问题：$\mathcal{Y} \in \{0, 1, \cdots, K\}$ 回归问题：$\mathcal{Y} \in R$ 结构学习 Learning with Different Data Label $y_n$按照数据的标签，可以把 ML 分为以下几类： supervised： 所有 $x_n$ 都具有 $y_n$ unsupervised： 所有 $x_n$ 都没有 $y_n$ semi-supervised： 一些 $x_n$ 具有 $y_n$ Learning with Different Protocol $f$按照数据的传输方式，可以把 ML 分为以下几类： batch： 一次性把所有的数据给算法 online： 连续的数据，一次处理一个数据 active： 机器通过主动询问某些问题来学习 Learning with Different Input Space $\mathcal{X}$按照数据的输入，可以把 ML 分为以下几类： concrete： 精细的、复杂的、有序的，已经完成预处理的数据 raw： 原始的，未经处理或者经过很少处理的数据 abstract：抽象的，无法轻易表明含义的数据]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NTU-ML-《机器学习基石》笔记系列]]></title>
    <url>%2F20180113-NTU-ML-0%2F</url>
    <content type="text"><![CDATA[前言“机器学习基石”是 Coursera 上一门关于机器学习的课程，由国立台湾大学的老师林轩田讲授。该课程一共有16节课，主要介绍了机器学习领域的基础理论知识。 授课大纲课程的大纲如下，以下的每个小项目对应到约一小时的课程： When Can Machines Learn? [何时可以使用机器学习]– The Learning Problem [机器学习问题]– Learning to Answer Yes/No [二元分类]– Types of Learning [各式机器学习问题]– Feasibility of Learning [机器学习的可行性] Why Can Machines Learn? [为什么机器可以学习]– Training versus Testing [训练与测试]– Theory of Generalization [举一反三的一般化理论]– The VC Dimension [VC 维度]– Noise and Error [噪声时错误] How Can Machines Learn? [机器可以怎么样学习]– Linear Regression [线性回归]– Linear Soft Classification [软性的线性分类]– Linear Classification beyond Yes/No [二元分类以外的分类问题]– Nonlinear Transformation [非线性转换] How Can Machines Learn Better? [机器可以怎么样学得更好]– Hazard of Overfitting [过度训练的危险]– Preventing Overfitting I: Regularization [避免过度训练一：控制调适]– Preventing Overfitting II: Validation [避免过度训练二：自我检测]– Three Learning Principles [三个机器学习的重要原则] 计划我将把课程按照自己的理解，整理成一份通俗易懂的笔记，一方面记录所学知识，另一方面与大家一起分享，共同进步。 点击右侧可关注我的 github 地址。 笔记链接]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
</search>
